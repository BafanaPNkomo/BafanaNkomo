{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Zindi XFD Attempt Simplified.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1ztj8UTM6gw",
        "colab_type": "text"
      },
      "source": [
        "# Honour Code\n",
        "I **Bafana, Nkomo**, confirm - by submitting my - that the solutions in this notebook are a result of my own work and that I abide by the EDSA honour code (https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n",
        "\n",
        "Non-compliance with the honour code constitutes a material breach of contract"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq2gI18NNG60",
        "colab_type": "text"
      },
      "source": [
        "# Importing Some Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJIeBUo9UcLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import datetime\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZBeS_hCNLUG",
        "colab_type": "text"
      },
      "source": [
        "#Loading Our Data Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1o3V-ogUgSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_sub = pd.read_csv('../content/sample_submission.csv')\n",
        "train = pd.read_csv('../content/training.csv')\n",
        "test = pd.read_csv('../content/test.csv')\n",
        "#var_def = pd.read_csv('../content/Xente_Variable_definitions.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqxOOQNfNQtF",
        "colab_type": "text"
      },
      "source": [
        "# Console Text Styles Simplified For Readibilty"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAQdPZ_huZ4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class bcolors:\n",
        "    HEADER = '\\033[95m'\n",
        "    #OKBLUE = '\\033[94m'\n",
        "    #OKGREEN = '\\033[92m'\n",
        "    #WARNING = '\\033[93m'\n",
        "    #FAIL = '\\033[91m'\n",
        "    ENDC = '\\033[0m'\n",
        "    BOLD = '\\033[1m'\n",
        "    UNDERLINE = '\\033[4m'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HsG20y2NmIB",
        "colab_type": "text"
      },
      "source": [
        "# Quick look at Our Dependent Variable in our Training Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSgUTFGzXk4T",
        "colab_type": "code",
        "outputId": "fcc548e9-d13f-4b05-c4d1-c97d7cfecf26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "target_count = train['FraudResult'].value_counts()\n",
        "print('NoFraud:', target_count[0])\n",
        "print('Fraud:', target_count[1])\n",
        "print('Proportion:', round(target_count[0] / target_count[1], 2), ': 1')\n",
        "\n",
        "target_count.plot(kind='bar', title='Legitimate Transactions 0 vs Fraudulent Transactions 1');"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NoFraud: 95469\n",
            "Fraud: 193\n",
            "Proportion: 494.66 : 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEFCAYAAAAfRLtkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmVk1h4aZmVVzaJiZWbX/D7bEwHa26fdFAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBdYC9aDYxg0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Class count\n",
        "count_legit, count_fraud = train['FraudResult'].value_counts()\n",
        "\n",
        "# Divide by class\n",
        "df_legit = train[train['FraudResult'] == 0]\n",
        "df_fraud = train[train['FraudResult'] == 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHwrNKjpOPav",
        "colab_type": "text"
      },
      "source": [
        "It looks like our data is imbalanced and something must be done here to combat a bias within our models. SO we resample to try and restablish some unbiasedness. To find out which resampling technique will work best here, we will go by trial and error to see which gives out the best result for each classification algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIFdct7vOwGQ",
        "colab_type": "text"
      },
      "source": [
        "# Resampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgy74DqBO5s4",
        "colab_type": "text"
      },
      "source": [
        "## Random Under Sampling\n",
        "TO illustrate the method here, all thats done is randomly taking less of the over represented outcome to match the number found in the under represented data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQuPOCCCZsxT",
        "colab_type": "code",
        "outputId": "8ef25f2c-fb1b-4491-ff08-318af99a99fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "source": [
        "df_legit_under = df_legit.sample(count_fraud)\n",
        "df_test_under = pd.concat([df_legit_under, df_fraud], axis=0)\n",
        "\n",
        "print('Random under-sampling:')\n",
        "print(df_test_under['FraudResult'].value_counts())\n",
        "\n",
        "df_test_under['FraudResult'].value_counts().plot(kind='bar', title='Count (FraudResult)');"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random under-sampling:\n",
            "1    193\n",
            "0    193\n",
            "Name: FraudResult, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEFCAYAAADt1CyEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJDXOoJekxv1/i8ZQdofmWRIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcihptJAbhhG",
        "colab_type": "text"
      },
      "source": [
        "##  Random over-sampling\n",
        "To illustrate the point, all that's done here is to randomly duplicate the under represented data enough enough times to match the over represented data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHoq_94zbk6C",
        "colab_type": "code",
        "outputId": "f948be8d-0577-4dea-9845-4e01025f7c4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "source": [
        "df_fraud_over = df_fraud.sample(count_legit, replace=True)\n",
        "df_test_over = pd.concat([df_legit, df_fraud_over], axis=0)\n",
        "\n",
        "print('Random over-sampling:')\n",
        "print(df_test_over['FraudResult'].value_counts())\n",
        "\n",
        "df_test_over['FraudResult'].value_counts().plot(kind='bar', title='Count (FraudResult)');"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random over-sampling:\n",
            "1    95469\n",
            "0    95469\n",
            "Name: FraudResult, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEFCAYAAAAfRLtkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xw9SuP9APbaQ",
        "colab_type": "text"
      },
      "source": [
        "We will use imblearn library to resample our data in different ways, but first lets have a look at our data set further"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "711wA46xcIU8",
        "colab_type": "text"
      },
      "source": [
        "# Missing Data\n",
        "We want to handle any missing found in our data especially our test data set since mainting TransactionIds is important there and handling missing data could go beyond just dropping missing columns or rows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc6N9Jac0DTX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#missing data\n",
        "def missing_check(df_check):\n",
        "  '''This function check a dataframe for missing values and returns the percentage of the missing values in each column as a dataframe'''\n",
        "  all_data_na = (df_check.isnull().sum() / len(df_check)) * 100\n",
        "  all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:30]\n",
        "  missing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\n",
        "  return missing_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krryZvlyQgVP",
        "colab_type": "text"
      },
      "source": [
        "We check the training data for missing values. If anuy mmissing values are found here, we will just delete the rows iin which they occur. There shouldn't be too many columns of concern."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ts6BmHFtqCk_",
        "colab_type": "code",
        "outputId": "304b9c20-c143-4b08-af33-ac2f854cbdd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "source": [
        "missing_check(train)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Missing Ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Missing Ratio]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wJ0lvpWQuUH",
        "colab_type": "text"
      },
      "source": [
        "We got lucky and it seems like there are no missing vallues in the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9Wlr2GiopUD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#we do not need this at this stage.\n",
        "#train.dropna(inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkijcrZ2Q6Z9",
        "colab_type": "text"
      },
      "source": [
        "We check the test set for missing data. If there are missing values here, we will have to impute the data should there be too many meaningful columns which have missing values. But we will see what happens first before we decide what to do."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvW410l0zau-",
        "colab_type": "code",
        "outputId": "b8893275-97ec-47a3-9c70-bfad626842f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "source": [
        "missing_check(test)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Missing Ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Missing Ratio]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8CS_phXp0T-",
        "colab_type": "text"
      },
      "source": [
        "Thank God! No misisng values in the test set. Ask no questions, hear no lies. We will move onto preparing our data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuOgzBP1RYOw",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing Officially  Begins"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odkIJ8oyRi3a",
        "colab_type": "text"
      },
      "source": [
        "We save our training data's FraudResult to a series for later use as well as the number of items in our training set and test set, and we finally save our training set and test set's TransactionId's."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfut4iGuUiu5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_final = train['FraudResult']\n",
        "ntrain = train.shape[0]\n",
        "ntest = test.shape[0]\n",
        "train_ID = train['TransactionId']\n",
        "test_ID = test['TransactionId']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oRb1PjcR4Z4",
        "colab_type": "text"
      },
      "source": [
        "We combine our train and test sets. From here we must be careful not to order or shuffle our data to preserve the TransactionIds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4v2HXuVUnGc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# combine 2 sets train then test\n",
        "all_data = pd.concat((train, test), sort=False).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2i6qW1uSSHTq",
        "colab_type": "text"
      },
      "source": [
        "We have to handle the TransactionStartTime column. We atomise this column all the way down to the minute the transaction was started. I feel that this may be important information. We then save these as integers and then we can move onto our next step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9mw-uoLUxFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_data['TransactionStartTime'] = pd.to_datetime(all_data['TransactionStartTime'])\n",
        "all_data['TransactionMinute'] = all_data['TransactionStartTime'].dt.minute\n",
        "all_data['TransactionHour'] = all_data['TransactionStartTime'].dt.hour\n",
        "all_data['TransactionDay'] = all_data['TransactionStartTime'].dt.day\n",
        "all_data['TransactionMonth'] = all_data['TransactionStartTime'].dt.month\n",
        "all_data['TransactionYear'] = all_data['TransactionStartTime'].dt.year"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-keSmxB0Zhqt",
        "colab_type": "code",
        "outputId": "634f35f7-e48e-4053-b3ec-0279e0fa68a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#check to see what columns we still have\n",
        "all_data.columns"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['TransactionId', 'BatchId', 'AccountId', 'SubscriptionId', 'CustomerId',\n",
              "       'CurrencyCode', 'CountryCode', 'ProviderId', 'ProductId',\n",
              "       'ProductCategory', 'ChannelId', 'Amount', 'Value',\n",
              "       'TransactionStartTime', 'PricingStrategy', 'FraudResult',\n",
              "       'TransactionMinute', 'TransactionHour', 'TransactionDay',\n",
              "       'TransactionMonth', 'TransactionYear'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq9y55ACTOF2",
        "colab_type": "text"
      },
      "source": [
        "## Let Dimensionality Reduction Begin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jp6LoHAYSqb3",
        "colab_type": "text"
      },
      "source": [
        "We want to be smart about how we select our features here. Time is limited and we would like to avoid making too many dummy variables. earlier tests gave out a combinede dataset of 3GB in size so since we are in a competition and we must watch the clock, we will avoid making dummies in the columns with thousands of unique entries and unique entries equal to the ttal number of transactions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hBymMMzsQmS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f53029c8-c4c0-455f-e8d3-f65182e16860"
      },
      "source": [
        "print('Number of Transactions:' + str(len(all_data)) + '\\n')\n",
        "\n",
        "for column in all_data.columns:\n",
        "  print(bcolors.BOLD + column + ':' + bcolors.ENDC )\n",
        "  print( \"Number of unique values:\" + str(len(all_data[column].unique())) + '\\n')\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Transactions:140681\n",
            "\n",
            "\u001b[1mTransactionId:\u001b[0m\n",
            "Number of unique values:140681\n",
            "\n",
            "\u001b[1mBatchId:\u001b[0m\n",
            "Number of unique values:139493\n",
            "\n",
            "\u001b[1mAccountId:\u001b[0m\n",
            "Number of unique values:4841\n",
            "\n",
            "\u001b[1mSubscriptionId:\u001b[0m\n",
            "Number of unique values:4836\n",
            "\n",
            "\u001b[1mCustomerId:\u001b[0m\n",
            "Number of unique values:7479\n",
            "\n",
            "\u001b[1mCurrencyCode:\u001b[0m\n",
            "Number of unique values:1\n",
            "\n",
            "\u001b[1mCountryCode:\u001b[0m\n",
            "Number of unique values:1\n",
            "\n",
            "\u001b[1mProviderId:\u001b[0m\n",
            "Number of unique values:6\n",
            "\n",
            "\u001b[1mProductId:\u001b[0m\n",
            "Number of unique values:27\n",
            "\n",
            "\u001b[1mProductCategory:\u001b[0m\n",
            "Number of unique values:10\n",
            "\n",
            "\u001b[1mChannelId:\u001b[0m\n",
            "Number of unique values:5\n",
            "\n",
            "\u001b[1mAmount:\u001b[0m\n",
            "Number of unique values:2099\n",
            "\n",
            "\u001b[1mValue:\u001b[0m\n",
            "Number of unique values:1880\n",
            "\n",
            "\u001b[1mTransactionStartTime:\u001b[0m\n",
            "Number of unique values:138574\n",
            "\n",
            "\u001b[1mPricingStrategy:\u001b[0m\n",
            "Number of unique values:4\n",
            "\n",
            "\u001b[1mFraudResult:\u001b[0m\n",
            "Number of unique values:3\n",
            "\n",
            "\u001b[1mTransactionMinute:\u001b[0m\n",
            "Number of unique values:60\n",
            "\n",
            "\u001b[1mTransactionHour:\u001b[0m\n",
            "Number of unique values:24\n",
            "\n",
            "\u001b[1mTransactionDay:\u001b[0m\n",
            "Number of unique values:31\n",
            "\n",
            "\u001b[1mTransactionMonth:\u001b[0m\n",
            "Number of unique values:5\n",
            "\n",
            "\u001b[1mTransactionYear:\u001b[0m\n",
            "Number of unique values:2\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTEVDwN5UyGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# These are the columns we chose to remove\n",
        "all_data.drop( columns = ['TransactionYear','TransactionId','BatchId', 'AccountId','CustomerId', 'SubscriptionId','TransactionStartTime', 'FraudResult', 'CountryCode', 'CurrencyCode', 'Value'], inplace = True )\n",
        "#all_data.drop(columns = ['TransactionId', 'ProductId','ProviderId', 'SubscriptionId','TransactionStartTime', 'FraudResult', 'CountryCode', 'CurrencyCode', 'Value'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6aNfn1oT5IV",
        "colab_type": "text"
      },
      "source": [
        "## Data types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A53DhXU7Tcda",
        "colab_type": "text"
      },
      "source": [
        "We want to maintain the right datatypes for our ML algorithms and calculations. SO we will monitor our datatypes and change the ones that do not match their description logically.For example: we can't have Amount as an int when Amount should be float etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2t0p0mZPyvcg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "dfe03552-3297-4128-c356-020239bd85eb"
      },
      "source": [
        "all_data.dtypes"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ProviderId            object\n",
              "ProductId             object\n",
              "ProductCategory       object\n",
              "ChannelId             object\n",
              "Amount               float64\n",
              "PricingStrategy        int64\n",
              "TransactionMinute      int64\n",
              "TransactionHour        int64\n",
              "TransactionDay         int64\n",
              "TransactionMonth       int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVctVvEDrlDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We turn PricingStrategy into a string since it is a categorical variable, specifically a nominal categorical varaible\n",
        "all_data['PricingStrategy'] = all_data['PricingStrategy'].astype('str') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhtpOGpyvW5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#At a later date, if there are more years to consider and not just 1 or 2, we will make year a categorical variable.\n",
        "#But there are a lot of years to go through in the set, we will keep year as an int, but for now year was dropped because \n",
        "#there were only 2 of them to consider and this would not tell us much about our data \n",
        "#all_data['TransactionYear'] = all_data['TransactionYear'].astype('str')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPOeTF7ji77D",
        "colab_type": "code",
        "outputId": "5f35d334-d71c-49b8-bdf0-b41ab6f4a372",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "source": [
        "#I still could not believe that there were no missing values in the training and test set so I checked again\n",
        "#Checking all_data will obviously yield missing values since the test set has no values for the FraudResult column\n",
        "missing_check(train)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Missing Ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Missing Ratio]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYqWKst1i7s8",
        "colab_type": "code",
        "outputId": "ae11b538-9fc3-4469-e852-ae42db6cce14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "source": [
        "missing_check(test)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Missing Ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Missing Ratio]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdrrzuYJz_hJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4n7hfz8U3B2",
        "colab_type": "text"
      },
      "source": [
        "## To Standardise or Normalise? That is the question.\n",
        "We want to see which performs best, if there's time, standardising or normalising. We will use Yeo-Johnson's Tranformation through PowerTransformer and MinMaScaler since they are not sensitive to outliers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHEjtDXtmas3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import PowerTransformer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3RtSlVQnK3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "power_transformer =  PowerTransformer(method='yeo-johnson')\n",
        "#all_data = pd.concat((all_data[['ProductCategory', 'ChannelId', 'PricingStrategy', 'TransactionYear']], \n",
        "#                      power_transformer.fit_transform(all_data[['TransactionMinute','TransactionHour',\n",
        "#                                                                 'TransactionDay','TransactionMonth',\n",
        "#                                                                 'TransactionYear','Amount']])), sort=False).reset_index(drop=True)\n",
        "transformed_cont =  power_transformer.fit_transform(all_data[['TransactionMinute','TransactionHour',\n",
        "                                                              'TransactionDay','TransactionMonth','Amount']])\n",
        "\n",
        "df = pd.DataFrame({'ProductCategory':all_data['ProductCategory'], 'ChannelId':all_data['ChannelId'], \n",
        "                   'PricingStrategy':all_data['PricingStrategy'], 'ProductId':all_data['ProductId'],\n",
        "                   'ProviderId':all_data['ProviderId'],\n",
        "                   'TransactionMinute': transformed_cont[:,0],'TransactionHour': transformed_cont[:,1], \n",
        "                   'TransactionDay': transformed_cont[:,2],'TransactionMonth': transformed_cont[:,3],\n",
        "                   'Amount': transformed_cont[:,4]})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0fcR1wAoRNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "minmax_scaler = MinMaxScaler()\n",
        "\n",
        "minmax_cont =  minmax_scaler.fit_transform(all_data[['TransactionMinute','TransactionHour',\n",
        "                                                              'TransactionDay','TransactionMonth','Amount']])\n",
        "\n",
        "df_minmax = pd.DataFrame({'ProductCategory':all_data['ProductCategory'], 'ChannelId':all_data['ChannelId'], \n",
        "                   'PricingStrategy':all_data['PricingStrategy'], 'ProductId':all_data['ProductId'],\n",
        "                   'ProviderId':all_data['ProviderId'],\n",
        "                   'TransactionMinute': transformed_cont[:,0],'TransactionHour': transformed_cont[:,1], \n",
        "                   'TransactionDay': transformed_cont[:,2],'TransactionMonth': transformed_cont[:,3],\n",
        "                   'Amount': transformed_cont[:,4]})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6Av3Ywt5-2t",
        "colab_type": "code",
        "outputId": "73d57de5-04dc-47cf-dc1a-13f6fb91e4a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#One last look at the datatypes after tranforming\n",
        "df.dtypes"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ProductCategory       object\n",
              "ChannelId             object\n",
              "PricingStrategy       object\n",
              "ProductId             object\n",
              "ProviderId            object\n",
              "TransactionMinute    float64\n",
              "TransactionHour      float64\n",
              "TransactionDay       float64\n",
              "TransactionMonth     float64\n",
              "Amount               float64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIaRxaxFVc40",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3800070d-a92b-4dea-f053-d31ae694af65"
      },
      "source": [
        "#minmax\n",
        "df_minmax.dtypes"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ProductCategory       object\n",
              "ChannelId             object\n",
              "PricingStrategy       object\n",
              "ProductId             object\n",
              "ProviderId            object\n",
              "TransactionMinute    float64\n",
              "TransactionHour      float64\n",
              "TransactionDay       float64\n",
              "TransactionMonth     float64\n",
              "Amount               float64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nbEdxvbVjxh",
        "colab_type": "text"
      },
      "source": [
        "**Note** MinMax looks like it will be more efficient than PoowerTransformer since the columns are stored as uint8 with values between [0,1] unlike PowerTransformer with float64 and values beyond [-1,1] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44UFnpP8WBTp",
        "colab_type": "text"
      },
      "source": [
        "# Let the headaches Begin:\n",
        "We get our dummy variable. In previous iterations of the notebook, choosing the 'wrong' features would crash our kernel through a memory error. After reading through the documentation and seeing how get_dummies 'gets dummies', we worked around the kernel crashing through using a for loop but this still took forever to run, so we considered converting to a sparse matrix or droping the features causing the slowness. In the end we dropped the features cauing the slowness. It is in line parsimoniousness, but one is unable to shake off the suspicion that there could be valuable information in the dropped columns. Luckily, time is not on our side and we will choose the most time friendly method: dropping the problem columns.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXKIiPKNU1gN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dummies\n",
        "#all_data = pd.get_dummies(all_data, drop_first=True) #crashes RAM\n",
        "all_data_cols = df.columns\n",
        "all_cat_cols = df.select_dtypes(exclude=np.number).columns\n",
        "all_data_plus = df\n",
        "#df_final = pd.get_dummies(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZDUF2VbU9K_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for column in all_cat_cols:\n",
        "  df = pd.get_dummies(all_data[[column]], drop_first=True)\n",
        "  all_data_plus =  pd.concat((all_data_plus, df), axis=1,sort=False, ignore_index=False)\n",
        "  all_data_plus.drop(columns=[column], inplace = True)\n",
        "  all_data_plus.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBvs9MZlzBSR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dummies\n",
        "#all_data = pd.get_dummies(all_data, drop_first=True) #crashes RAM\n",
        "minmax_cols = df_minmax.columns\n",
        "minmax_cat_cols = df_minmax.select_dtypes(exclude=np.number).columns\n",
        "minmax_data_plus = df_minmax\n",
        "#df_final = pd.get_dummies(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwOLyGJ_zBEZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for column in minmax_cat_cols:\n",
        "  df_minmax = pd.get_dummies(all_data[[column]], drop_first=True)\n",
        "  minmax_data_plus =  pd.concat((minmax_data_plus, df_minmax), axis=1,sort=False, ignore_index=False)\n",
        "  minmax_data_plus.drop(columns=[column], inplace = True)\n",
        "  minmax_data_plus.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGKEJXnSVTk7",
        "colab_type": "code",
        "outputId": "bffd4646-fbeb-4288-dd25-c12114908c6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "#what are our new columns?\n",
        "all_data_plus.columns"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['TransactionMinute', 'TransactionHour', 'TransactionDay',\n",
              "       'TransactionMonth', 'Amount', 'ProductCategory_data_bundles',\n",
              "       'ProductCategory_financial_services', 'ProductCategory_movies',\n",
              "       'ProductCategory_other', 'ProductCategory_retail',\n",
              "       'ProductCategory_ticket', 'ProductCategory_transport',\n",
              "       'ProductCategory_tv', 'ProductCategory_utility_bill',\n",
              "       'ChannelId_ChannelId_2', 'ChannelId_ChannelId_3',\n",
              "       'ChannelId_ChannelId_4', 'ChannelId_ChannelId_5', 'PricingStrategy_1',\n",
              "       'PricingStrategy_2', 'PricingStrategy_4', 'ProductId_ProductId_10',\n",
              "       'ProductId_ProductId_11', 'ProductId_ProductId_12',\n",
              "       'ProductId_ProductId_13', 'ProductId_ProductId_14',\n",
              "       'ProductId_ProductId_15', 'ProductId_ProductId_16',\n",
              "       'ProductId_ProductId_17', 'ProductId_ProductId_18',\n",
              "       'ProductId_ProductId_19', 'ProductId_ProductId_2',\n",
              "       'ProductId_ProductId_20', 'ProductId_ProductId_21',\n",
              "       'ProductId_ProductId_22', 'ProductId_ProductId_23',\n",
              "       'ProductId_ProductId_24', 'ProductId_ProductId_25',\n",
              "       'ProductId_ProductId_26', 'ProductId_ProductId_27',\n",
              "       'ProductId_ProductId_3', 'ProductId_ProductId_4',\n",
              "       'ProductId_ProductId_5', 'ProductId_ProductId_6',\n",
              "       'ProductId_ProductId_7', 'ProductId_ProductId_8',\n",
              "       'ProductId_ProductId_9', 'ProviderId_ProviderId_2',\n",
              "       'ProviderId_ProviderId_3', 'ProviderId_ProviderId_4',\n",
              "       'ProviderId_ProviderId_5', 'ProviderId_ProviderId_6'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwGSN8f7ht18",
        "colab_type": "code",
        "outputId": "a46d9b40-1774-4b05-9182-7431afead50c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "source": [
        "#The last missing data check, its safe to do this here since there is no column for FraudResult\n",
        "missing_check(all_data_plus)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Missing Ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Missing Ratio]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp9QHkDZXSrB",
        "colab_type": "text"
      },
      "source": [
        "# Filing in the Divorce Papers: Train and Test Must Be split\n",
        "Here we split the data back to train and test just like they were in the csv files however they have changed somewhat during prprocessing and have columns and entries prepped and ready for us to use for further steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUzLnBsTVWqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xtrain = all_data_plus[:ntrain]\n",
        "Xtest = all_data_plus[ntrain:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05D3n6TAJ6bi",
        "colab_type": "code",
        "outputId": "c97b83bf-27e9-42aa-b00f-2a327cbc4856",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "Xtrain.head()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionMinute</th>\n",
              "      <th>TransactionHour</th>\n",
              "      <th>TransactionDay</th>\n",
              "      <th>TransactionMonth</th>\n",
              "      <th>Amount</th>\n",
              "      <th>ProductCategory_data_bundles</th>\n",
              "      <th>ProductCategory_financial_services</th>\n",
              "      <th>ProductCategory_movies</th>\n",
              "      <th>ProductCategory_other</th>\n",
              "      <th>ProductCategory_retail</th>\n",
              "      <th>ProductCategory_ticket</th>\n",
              "      <th>ProductCategory_transport</th>\n",
              "      <th>ProductCategory_tv</th>\n",
              "      <th>ProductCategory_utility_bill</th>\n",
              "      <th>ChannelId_ChannelId_2</th>\n",
              "      <th>ChannelId_ChannelId_3</th>\n",
              "      <th>ChannelId_ChannelId_4</th>\n",
              "      <th>ChannelId_ChannelId_5</th>\n",
              "      <th>PricingStrategy_1</th>\n",
              "      <th>PricingStrategy_2</th>\n",
              "      <th>PricingStrategy_4</th>\n",
              "      <th>ProductId_ProductId_10</th>\n",
              "      <th>ProductId_ProductId_11</th>\n",
              "      <th>ProductId_ProductId_12</th>\n",
              "      <th>ProductId_ProductId_13</th>\n",
              "      <th>ProductId_ProductId_14</th>\n",
              "      <th>ProductId_ProductId_15</th>\n",
              "      <th>ProductId_ProductId_16</th>\n",
              "      <th>ProductId_ProductId_17</th>\n",
              "      <th>ProductId_ProductId_18</th>\n",
              "      <th>ProductId_ProductId_19</th>\n",
              "      <th>ProductId_ProductId_2</th>\n",
              "      <th>ProductId_ProductId_20</th>\n",
              "      <th>ProductId_ProductId_21</th>\n",
              "      <th>ProductId_ProductId_22</th>\n",
              "      <th>ProductId_ProductId_23</th>\n",
              "      <th>ProductId_ProductId_24</th>\n",
              "      <th>ProductId_ProductId_25</th>\n",
              "      <th>ProductId_ProductId_26</th>\n",
              "      <th>ProductId_ProductId_27</th>\n",
              "      <th>ProductId_ProductId_3</th>\n",
              "      <th>ProductId_ProductId_4</th>\n",
              "      <th>ProductId_ProductId_5</th>\n",
              "      <th>ProductId_ProductId_6</th>\n",
              "      <th>ProductId_ProductId_7</th>\n",
              "      <th>ProductId_ProductId_8</th>\n",
              "      <th>ProductId_ProductId_9</th>\n",
              "      <th>ProviderId_ProviderId_2</th>\n",
              "      <th>ProviderId_ProviderId_3</th>\n",
              "      <th>ProviderId_ProviderId_4</th>\n",
              "      <th>ProviderId_ProviderId_5</th>\n",
              "      <th>ProviderId_ProviderId_6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.565147</td>\n",
              "      <td>-2.140289</td>\n",
              "      <td>0.071567</td>\n",
              "      <td>1.226264</td>\n",
              "      <td>0.019220</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.502868</td>\n",
              "      <td>-2.140289</td>\n",
              "      <td>0.071567</td>\n",
              "      <td>1.226264</td>\n",
              "      <td>0.006675</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.852493</td>\n",
              "      <td>-2.140289</td>\n",
              "      <td>0.071567</td>\n",
              "      <td>1.226264</td>\n",
              "      <td>0.013482</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.240559</td>\n",
              "      <td>-1.933063</td>\n",
              "      <td>0.071567</td>\n",
              "      <td>1.226264</td>\n",
              "      <td>0.201230</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.346543</td>\n",
              "      <td>-1.933063</td>\n",
              "      <td>0.071567</td>\n",
              "      <td>1.226264</td>\n",
              "      <td>-0.010988</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionMinute  ...  ProviderId_ProviderId_6\n",
              "0          -0.565147  ...                        1\n",
              "1          -0.502868  ...                        0\n",
              "2           0.852493  ...                        1\n",
              "3           0.240559  ...                        0\n",
              "4           0.346543  ...                        0\n",
              "\n",
              "[5 rows x 52 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N297pFyEqq4B",
        "colab_type": "text"
      },
      "source": [
        "# Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKhK1YjIqts-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import  train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(Xtrain, y_train_final, test_size = 0.2, random_state = 1111 )\n",
        "#try 75/25 - I had already passed my submission limit and could not test these\n",
        "#try 90/10 - I had already passed my submission limit and could not test these\n",
        "#try 50/50 - I had already passed my submission limit and could not test these\n",
        "#try 60/40 - I had already passed my submission limit and could not test these\n",
        "#try 85/15 - I had already passed my submission limit and could not test these\n",
        "#luckily I found a satissfactory result with my last entry into the competition whch I am haappy with. I beat laura_the_explorer, for now..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKBfZqL56Ri2",
        "colab_type": "text"
      },
      "source": [
        "# Resampling\n",
        "As promised, we dive into resampling for real this time. We prep all the resampling techniques that we know of for the next steps. In this case I suspect that Over Sampling will work best here, but I stand to be corrected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6dK5wprg8Oj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "3e81fd37-65ab-4234-a78a-445436d2ed49"
      },
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "rus = RandomUnderSampler(return_indices=True)\n",
        "X_rus, y_rus, id_rus = rus.fit_sample(X_train, y_train)\n",
        "X_rus = pd.DataFrame(data=X_rus, columns=X_train.columns)\n",
        "y_rus= pd.DataFrame(data=y_rus,columns=['FraudResult'])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DJkXgv9g1K9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "ros = RandomOverSampler()\n",
        "X_ros, y_ros = ros.fit_sample(X_train, y_train)\n",
        "X_ros = pd.DataFrame(data=X_ros, columns=X_train.columns)\n",
        "y_ros= pd.DataFrame(data=y_ros,columns=['FraudResult'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FynzKDwVguCC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imblearn.under_sampling import TomekLinks\n",
        "\n",
        "tl = TomekLinks(return_indices=True, ratio='majority')\n",
        "X_tl, y_tl, id_tl = tl.fit_sample(X_train, y_train)\n",
        "X_tl = pd.DataFrame(data=X_tl, columns=X_train.columns)\n",
        "y_tl= pd.DataFrame(data=y_tl,columns=['FraudResult'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxY-GLxyea94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imblearn.under_sampling import ClusterCentroids\n",
        "\n",
        "cc = ClusterCentroids(ratio='auto')\n",
        "X_cc, y_cc = cc.fit_sample(X_train, y_train)\n",
        "X_cc = pd.DataFrame(data=X_cc, columns=X_train.columns)\n",
        "y_cc= pd.DataFrame(data=y_cc,columns=['FraudResult'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1YtvLCLgBAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imblearn.over_sampling import SMOTE \n",
        "smote_algo = SMOTE(random_state=1111)\n",
        "X_smote, y_smote = smote_algo.fit_sample(X_train, y_train)\n",
        "X_smote = pd.DataFrame(data=X_smote, columns=X_train.columns)\n",
        "y_smote = pd.DataFrame(data=y_smote,columns=['FraudResult'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1_hqoKmdjSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imblearn.combine import SMOTETomek\n",
        "\n",
        "smt = SMOTETomek(ratio='auto', random_state=1111)\n",
        "X_smt, y_smt = smt.fit_sample(Xtrain, y_train_final)\n",
        "X_smt = pd.DataFrame(data=X_smt, columns=Xtrain.columns)\n",
        "y_smt = pd.DataFrame(data=y_smt,columns=['FraudResult'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BwTDVg9x8ph",
        "colab_type": "text"
      },
      "source": [
        "# Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3spc2aC5wtI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6a085b77-1b4c-4051-b157-8710725f7c81"
      },
      "source": [
        "#This what we want our csv to look like in the end, so we will abuild a function \n",
        "#to stop ourselves from committing the sin of repeated code\n",
        "sample_sub.head()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionId</th>\n",
              "      <th>FraudResult</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TransactionId_50600</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TransactionId_95109</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TransactionId_47357</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TransactionId_28185</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TransactionId_22140</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         TransactionId  FraudResult\n",
              "0  TransactionId_50600          NaN\n",
              "1  TransactionId_95109          NaN\n",
              "2  TransactionId_47357          NaN\n",
              "3  TransactionId_28185          NaN\n",
              "4  TransactionId_22140          NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zy2ekRLHyAlp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def output_csv(file_name, preds):\n",
        "  '''This function outputs a csv in the format required by the Zindi competition\n",
        "  0 input is replaced with Nan and the index is replaced with TransactionId '''\n",
        "  \n",
        "  output=pd.DataFrame({'TransactionId':test_ID.values, 'FraudResult': preds })\n",
        "  output['FraudResult'] =  output['FraudResult'].replace({0:np.nan})\n",
        "  output.set_index('TransactionId', inplace = True)\n",
        "  output.to_csv(file_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCymvJHSZA4B",
        "colab_type": "text"
      },
      "source": [
        "# Let the Hunt Begin:\n",
        "Our goal is to find a model which has an f1-score of above 0.70 in the finala Zindi submission. We will try to apply model selection techniques learned in this sprint, but for safety, we will first keep things simple and run everything with default hyperparameter values. We will start with the algorithms which I suspect will give out the best results in the fastest time and escalate the complexity from there, that is, we will concentrate on RandomForestClassifier, LogisticRegressor and GaussianNaiveBayes First, then we will try out others e.g. KNN, AdaBoostClassifier, XGBoostClassifier and others. \n",
        "Note that we still have to test out all of the resampling techniques as well.\n",
        "\n",
        "**Note:** I was under the impression that unlike Kaggle, we wold have an unlimited number of submissions. I was tempted to create a dishonest second profile to enter more submissions in, but I had already achieved a score above 0.7 by the time I ranout of submissions (Thank you Random Forest Classifier and SMOTE Resampling)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBzxv8hB6H3p",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7el-MY2oVaix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vb3Sng8W6r2s",
        "colab_type": "text"
      },
      "source": [
        "#### No Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "334-yNwX65C7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "a7ee9539-3aac-4ea4-cfc2-b20ebb812997"
      },
      "source": [
        "rfc = forest = RandomForestClassifier(random_state=1111)\n",
        "rfc.fit(Xtrain, y_train_final)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
              "                       n_jobs=None, oob_score=False, random_state=1111,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zF0-pHeD7Clf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "8c9d58a0-10c2-44af-9620-5a983d902343"
      },
      "source": [
        "rfc_no_split_train_o_preds = rfc.predict(Xtrain)\n",
        "rfc_no_split_final_preds = rfc.predict(Xtest)\n",
        "rfc_no_split_train_preds = rfc.predict(X_train)\n",
        "rfc_no_split_test_preds = rfc.predict(X_test)\n",
        "\n",
        "\n",
        "print(bcolors.BOLD + 'RFC No Split f1_scores:' + bcolors.ENDC)\n",
        "print('X_train: '+ str(f1_score(y_train, rfc_no_split_train_preds)))\n",
        "print('X_test: ' + str(f1_score(y_test, rfc_no_split_test_preds)))\n",
        "print('\\nTrain Data: ' + str(f1_score(y_train_final, rfc_no_split_train_o_preds)))"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mRFC No Split f1_scores:\u001b[0m\n",
            "X_train: 0.9908814589665653\n",
            "X_test: 1.0\n",
            "\n",
            "Train Data: 0.9921671018276762\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svH1vwCP7YAu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_csv('RFC NoSplit NoSpecial.csv', rfc_no_split_final_preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jk-tX4cKhD2i",
        "colab_type": "text"
      },
      "source": [
        ">>**Zindi Score:** (Unable to submit, submission limit passed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZqQ66eX6z2v",
        "colab_type": "text"
      },
      "source": [
        "#### With Train Test Split No resampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWuZcLmyVdWO",
        "colab_type": "code",
        "outputId": "15b9a95a-8deb-4fbd-b491-f9ce887f6b05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "forest = RandomForestClassifier(random_state=1111)\n",
        "forest.fit(X_train, y_train)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
              "                       n_jobs=None, oob_score=False, random_state=1111,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCk3EmvI4z0G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6ca8303f-1838-4929-dd3e-d22f484e458f"
      },
      "source": [
        "# In preparation for GridSearchCV, I'm still trying to learn what the fastest \n",
        "# implementation would be and I just might not be able to get to this step before 3pm\n",
        "# but I'll leave my template in here just in case.\n",
        "\n",
        "'''n_estimators = [1, 2, 3, 4, 5, 10, 20, 50, 100, 300, 500, 800, 1200]\n",
        "max_depth = [5, 8, 15, 25, 30]\n",
        "min_samples_split = [2, 5, 10, 15, 100]\n",
        "min_samples_leaf = [1, 2, 5, 10] \n",
        "\n",
        "hyperF = dict(n_estimators = n_estimators, max_depth = max_depth,  \n",
        "              min_samples_split = min_samples_split, \n",
        "             min_samples_leaf = min_samples_leaf)\n",
        "\n",
        "gridF = GridSearchCV(forest, hyperF, cv = 3, verbose = 1, \n",
        "                      n_jobs = -1)\n",
        "bestF = gridF.fit(Xtrain, y_train_final)\n",
        "\n",
        "#########################################################################\n",
        "#default hyperparameters\n",
        "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
        "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
        "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                       min_samples_leaf=1, min_samples_split=2,\n",
        "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
        "                       n_jobs=None, oob_score=False, random_state=1111,\n",
        "                       verbose=0, warm_start=False)\n",
        "'''"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"n_estimators = [1, 2, 3, 4, 5, 10, 20, 50, 100, 300, 500, 800, 1200]\\nmax_depth = [5, 8, 15, 25, 30]\\nmin_samples_split = [2, 5, 10, 15, 100]\\nmin_samples_leaf = [1, 2, 5, 10] \\n\\nhyperF = dict(n_estimators = n_estimators, max_depth = max_depth,  \\n              min_samples_split = min_samples_split, \\n             min_samples_leaf = min_samples_leaf)\\n\\ngridF = GridSearchCV(forest, hyperF, cv = 3, verbose = 1, \\n                      n_jobs = -1)\\nbestF = gridF.fit(Xtrain, y_train_final)\\n\\n#########################################################################\\n#default hyperparameters\\nRandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\\n                       max_depth=None, max_features='auto', max_leaf_nodes=None,\\n                       min_impurity_decrease=0.0, min_impurity_split=None,\\n                       min_samples_leaf=1, min_samples_split=2,\\n                       min_weight_fraction_leaf=0.0, n_estimators=10,\\n                       n_jobs=None, oob_score=False, random_state=1111,\\n                       verbose=0, warm_start=False)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1M-EGLnA1du1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "841814f2-3d72-476c-e8ac-9b5c25ea2cb7"
      },
      "source": [
        "rfc_train_preds = forest.predict(X_train)\n",
        "rfc_test_preds = forest.predict(X_test)\n",
        "rfc_train_o_preds = forest.predict(Xtrain)\n",
        "rfc_final_preds = forest.predict(Xtest)\n",
        "\n",
        "\n",
        "print(bcolors.BOLD + 'RFC F1_Scores train_test_split Only' + bcolors.ENDC)\n",
        "print('X_train Data: ' + str(f1_score(y_train, rfc_train_preds)))\n",
        "print('X_test Data:' + str(f1_score(y_test, rfc_test_preds)))\n",
        "print('\\nTrain Data:' + str(f1_score(y_train_final, rfc_train_o_preds)))"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mRFC F1_Scores train_test_split Only\u001b[0m\n",
            "X_train Data: 0.9815950920245399\n",
            "X_test Data:0.7924528301886792\n",
            "\n",
            "Train Data:0.9551451187335093\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpfZFLt-5WLr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_csv('RFC Split.csv', rfc_final_preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5t3QcZQDDsB",
        "colab_type": "text"
      },
      "source": [
        ">>  **Zindi Score:** 0.612244897959184\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTOvJVk85J-W",
        "colab_type": "text"
      },
      "source": [
        "#### RandomUnderSampling Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2SNDQ8Z2zo3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "132474c4-6535-4bdf-a98c-6e821ae825a0"
      },
      "source": [
        "rfc_rus = RandomForestClassifier(random_state=1111)\n",
        "rfc_rus.fit(X_rus, y_rus)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
              "                       n_jobs=None, oob_score=False, random_state=1111,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87ipDFFa3CBO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "d4a40add-17b1-4f78-c08a-5b5c36b2b40e"
      },
      "source": [
        "rfc_rus_train_preds = rfc_rus.predict(X_rus)\n",
        "rfc_rus_test_preds = rfc_rus.predict(X_test)\n",
        "rfc_rus_train_o_preds = rfc_rus.predict(Xtrain)\n",
        "rfc_rus_final_preds = rfc_rus.predict(Xtest)\n",
        "\n",
        "\n",
        "print(bcolors.BOLD + 'Random Forest Classifier' + bcolors.ENDC)\n",
        "print('X_train Data: ' + str(f1_score(y_rus, rfc_rus_train_preds)))\n",
        "print('X_test Data:' + str(f1_score(y_test, rfc_rus_test_preds)))\n",
        "print('\\nTest Data:' + str(f1_score(y_train_final, rfc_rus_train_o_preds)))"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mRandom Forest Classifier\u001b[0m\n",
            "X_train Data: 1.0\n",
            "X_test Data:0.13368983957219252\n",
            "\n",
            "Test Data:0.21766381766381768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKxgPaOu6k0_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_csv('RFC RUS.csv', rfc_rus_final_preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHDT7Kb_DPUn",
        "colab_type": "text"
      },
      "source": [
        ">> **Zindi Score:** 0.141242937853107"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGlOOYOC804T",
        "colab_type": "text"
      },
      "source": [
        "### RFC Random Oversampling Results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDpdVPFc3jyv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "ac42d00f-9e7e-441e-c261-105c01b93d92"
      },
      "source": [
        "rfc_ros = RandomForestClassifier(random_state=1111)\n",
        "rfc_ros.fit(X_ros, y_ros)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
              "                       n_jobs=None, oob_score=False, random_state=1111,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD_wfbbl8_XR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "87633003-9544-485c-d131-0295da18bf12"
      },
      "source": [
        "rfc_ros_train_preds = rfc_ros.predict(X_ros)\n",
        "rfc_ros_test_preds = rfc_ros.predict(X_test)\n",
        "rfc_ros_train_o_preds = rfc_ros.predict(Xtrain)\n",
        "rfc_ros_final_preds = rfc_ros.predict(Xtest)\n",
        "\n",
        "\n",
        "print(bcolors.BOLD + 'Random Forest Classifier' + bcolors.ENDC)\n",
        "print('X_train Data: ' + str(f1_score(y_ros, rfc_ros_train_preds)))\n",
        "print('X_test Data:' + str(f1_score(y_test, rfc_ros_test_preds)))\n",
        "print('\\nTrain Data:' + str(f1_score(y_train_final, rfc_ros_train_o_preds)))"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mRandom Forest Classifier\u001b[0m\n",
            "X_train Data: 0.9999934523692602\n",
            "X_test Data:0.7169811320754716\n",
            "\n",
            "Train Data:0.9585492227979274\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajYuerLU1KnR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_csv( 'RFC ROS 80-20.csv', rfc_ros_final_preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRbrtP5SDewm",
        "colab_type": "text"
      },
      "source": [
        ">> **Zindi Score:** 0.679245283018868  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqUP7MBb9Uk3",
        "colab_type": "text"
      },
      "source": [
        "### RFC TomekLinks results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORyDE7NB9dyE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "7642ba84-5430-4aa2-9cbb-fd465f68e2cb"
      },
      "source": [
        "rfc_tl = RandomForestClassifier( random_state = 1111 )\n",
        "rfc_tl.fit(X_tl, y_tl) "
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
              "                       n_jobs=None, oob_score=False, random_state=1111,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wi54Mnf93XI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "296a5421-a3b1-4251-ef61-b3fdc0f928f1"
      },
      "source": [
        "rfc_tl_train_preds = rfc_tl.predict(X_tl)\n",
        "rfc_tl_test_preds = rfc_tl.predict(X_test)\n",
        "rfc_tl_test_o_preds = rfc_tl.predict(Xtrain)\n",
        "rfc_tl_final_preds = rfc_tl.predict(Xtest)\n",
        "\n",
        "\n",
        "print(bcolors.BOLD + 'Random Forest Classifier' + bcolors.ENDC)\n",
        "print('X_train Data: ' + str(f1_score(y_tl, rfc_tl_train_preds)))\n",
        "print('X_test Data:' + str(f1_score(y_test, rfc_tl_test_preds)))\n",
        "\n",
        "print('\\nTest Data:' + str(f1_score(y_train_final, rfc_ros_train_o_preds)))"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mRandom Forest Classifier\u001b[0m\n",
            "X_train Data: 0.9908814589665653\n",
            "X_test Data:0.7636363636363638\n",
            "\n",
            "Test Data:0.9585492227979274\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snk1dq0e-BAe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_csv( 'RFC TomekLinks 80-20.csv', rfc_tl_final_preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4hzXH6-Dl72",
        "colab_type": "text"
      },
      "source": [
        ">> **ZindiScore:** 0.64406779661017"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipB6aesk_KQ5",
        "colab_type": "text"
      },
      "source": [
        "### RFC ClusterCentroids results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CYmotNr_Ns6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "66467b0c-9ace-4228-f8ca-c567fa3c2c26"
      },
      "source": [
        "rfc_cc = RandomForestClassifier( random_state = 1111 )\n",
        "rfc_cc.fit(X_cc, y_cc)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
              "                       n_jobs=None, oob_score=False, random_state=1111,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fvwjIwP_XQ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "e9290b52-c414-49fd-ce44-84d1f4e3f417"
      },
      "source": [
        "rfc_cc_train_preds = rfc_cc.predict( X_cc )\n",
        "rfc_cc_test_preds = rfc_cc.predict( X_test )\n",
        "\n",
        "rfc_cc_train_o_preds = rfc_cc.predict( Xtrain )\n",
        "rfc_cc_final_preds = rfc_cc.predict( Xtest )\n",
        "\n",
        "print(bcolors.BOLD + 'Random Forest Classifier' + bcolors.ENDC)\n",
        "print('X_train Data: ' + str(f1_score(y_cc, rfc_cc_train_preds)))\n",
        "print('X_test Data:' + str(f1_score(y_test, rfc_cc_test_preds)))\n",
        "print('\\nTest Data:' + str(f1_score(y_train_final, rfc_cc_train_o_preds)))\n"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mRandom Forest Classifier\u001b[0m\n",
            "X_train Data: 1.0\n",
            "X_test Data:0.0028214640263336645\n",
            "\n",
            "Test Data:0.004030784332153337\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7sV_luW_-Nr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_csv( 'RFC ClusterCentroids ratio 0-10 80-20_split.csv', rfc_cc_final_preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWHhBHgODtS0",
        "colab_type": "text"
      },
      "source": [
        ">> **ZindiScore:** 0.00224890927899969"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKeqZOCeAtmi",
        "colab_type": "text"
      },
      "source": [
        "### RFC SMOTE results "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b69Lhi6MA-o-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "704565c5-4acb-41d1-b78b-ceb47513d0a2"
      },
      "source": [
        "rfc_smote  = RandomForestClassifier( random_state = 1111 )\n",
        "rfc_smote.fit(X_smote, y_smote)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
              "                       n_jobs=None, oob_score=False, random_state=1111,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Prfw6BLANBJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "37062db4-434f-4744-aea4-79100dfe4f35"
      },
      "source": [
        "rfc_smote_train_preds = rfc_smote.predict(X_smote)\n",
        "rfc_smote_test_preds = rfc_smote.predict(X_test)\n",
        "rfc_smote_train_o_preds = rfc_smote.predict(Xtrain)\n",
        "rfc_smote_final_preds = rfc_smote.predict(Xtest)\n",
        "\n",
        "print(bcolors.BOLD + 'Random Forest Classifier' + bcolors.ENDC)\n",
        "print('X_train Data: ' + str(f1_score(y_smote, rfc_smote_train_preds)))\n",
        "print('X_test Data:' + str(f1_score(y_test, rfc_smote_test_preds)))\n",
        "print('\\nTrain Data:' + str(f1_score(y_train_final, rfc_smote_train_o_preds)))"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mRandom Forest Classifier\u001b[0m\n",
            "X_train Data: 0.9999541653843886\n",
            "X_test Data:0.7931034482758621\n",
            "\n",
            "Train Data:0.9509043927648577\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xz0peU12B-xn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_csv('RFC SMOTE 80-20_split.csv', rfc_smote_final_preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DNeI3oyDzzm",
        "colab_type": "text"
      },
      "source": [
        ">> **Zindi Score:** 0.735294117647059"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJeIVLkdD87Z",
        "colab_type": "text"
      },
      "source": [
        "### RFC SMOTETomekLinks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgZJLbqED6Uy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "e4b961df-9d94-4594-d794-a210b95fa2b9"
      },
      "source": [
        "rfc_smt = RandomForestClassifier( random_state = 1111 )\n",
        "rfc_smt.fit(X_smt, y_smt)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
              "                       n_jobs=None, oob_score=False, random_state=1111,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLYFTcZcENT7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "39980450-ae2d-4f26-9e7c-bf324f045dfe"
      },
      "source": [
        "rfc_smt_train_preds = rfc_smt.predict(X_smt)\n",
        "rfc_smt_test_preds = rfc_smt.predict(X_test)\n",
        "rfc_smt_train_o_preds = rfc_smt.predict(Xtrain)\n",
        "rfc_smt_final_preds = rfc_smt.predict(Xtest)\n",
        "\n",
        "print(bcolors.BOLD + 'Random Forest Classifier' + bcolors.ENDC)\n",
        "print('X_train Data: ' + str(f1_score(y_smt, rfc_smt_train_preds)))\n",
        "print('X_test Data:' + str(f1_score(y_test, rfc_smt_test_preds)))\n",
        "print('\\nTrain Data:' + str(f1_score(y_train_final, rfc_smt_train_o_preds)))"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mRandom Forest Classifier\u001b[0m\n",
            "X_train Data: 0.9999842878466494\n",
            "X_test Data:1.0\n",
            "\n",
            "Train Data:0.9921671018276762\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_jUsNRaEoPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_csv('RFC SMOTETomek 80-20_split.csv', rfc_smt_final_preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyY5p1mQEsdl",
        "colab_type": "text"
      },
      "source": [
        ">> **Zindi Score:** (Could not submit, max number of Daily Submissions exceeded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fX3rYzMn57S5",
        "colab_type": "text"
      },
      "source": [
        "## Logistic Regression\n",
        "I was unable to test out the rest of the submissions and time was close to running out at this stage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOBKHxvnVo-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcM7_VyCVpWE",
        "colab_type": "code",
        "outputId": "2a4f67e9-a54c-4ecf-b97a-8357d045ab9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "logistic_c1 = LogisticRegression(C=1, random_state=1111)\n",
        "logistic_c2 = LogisticRegression(C=2, random_state=1111)\n",
        "logistic_c5 = LogisticRegression(C=5, random_state=1111)\n",
        "logistic_c8 = LogisticRegression(C=8, random_state=1111)\n",
        "logistic_c10 = LogisticRegression(C=10, random_state=1111)\n",
        "\n",
        "logistic_c1.fit( Xtrain, y_train_final )\n",
        "logistic_c2.fit( Xtrain, y_train_final )\n",
        "logistic_c5.fit( Xtrain, y_train_final )\n",
        "logistic_c10.fit( Xtrain, y_train_final )"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
              "                   random_state=1111, solver='warn', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsIISBn4JV4s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "d1c04e4a-8f2a-44b4-fe0f-096766904f1c"
      },
      "source": [
        "log_c1_train_preds = logistic_c1.predict(X_train)\n",
        "log_c1_test_preds = logistic_c1.predict(X_test)\n",
        "log_c1_final_preds = logistic_c1.predict(Xtest)\n",
        "\n",
        "print(bcolors.BOLD + 'Logistic Regression C=1' + bcolors.ENDC)\n",
        "print('Train Data: ' + str(f1_score(y_train, log_c1_train_preds)))\n",
        "print('Test Data:' + str(f1_score(y_test, log_c1_test_preds)))\n",
        "\n",
        "log_c5_train_preds = logistic_c5.predict(X_train)\n",
        "log_c5_test_preds = logistic_c5.predict(X_test)\n",
        "log_c5_final_preds = logistic_c5.predict(Xtest)\n",
        "\n",
        "print(bcolors.BOLD + 'Logistic Regression C=5' + bcolors.ENDC)\n",
        "print('Train Data: ' + str(f1_score(y_train, log_c5_train_preds)))\n",
        "print('Test Data:' + str(f1_score(y_test, log_c5_test_preds)))\n",
        "\n",
        "\n",
        "log_c10_train_preds = logistic_c10.predict(X_train)\n",
        "log_c10_test_preds = logistic_c10.predict(X_test)\n",
        "log_c10_final_preds = logistic_c10.predict(Xtest)\n",
        "\n",
        "\n",
        "print(bcolors.BOLD + 'Logistic Regression C=10' + bcolors.ENDC)\n",
        "print('Train Data: ' + str(f1_score(y_train, log_c10_train_preds)))\n",
        "print('Test Data:' + str(f1_score(y_test, log_c10_test_preds)))"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mLogistic Regression C=1\u001b[0m\n",
            "Train Data: 0.44537815126050423\n",
            "Test Data:0.27906976744186046\n",
            "\u001b[1mLogistic Regression C=5\u001b[0m\n",
            "Train Data: 0.4647302904564315\n",
            "Test Data:0.27906976744186046\n",
            "\u001b[1mLogistic Regression C=10\u001b[0m\n",
            "Train Data: 0.4628099173553719\n",
            "Test Data:0.27272727272727276\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nML-7_MrH_kn",
        "colab_type": "text"
      },
      "source": [
        "## AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vd_bWbaAWuV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUsiY4stKMFV",
        "colab_type": "text"
      },
      "source": [
        ">### No Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_H4WJ-YIWv57",
        "colab_type": "code",
        "outputId": "29891eba-20d8-49e6-fcd1-2ea661de5475",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "adaboost = AdaBoostClassifier( random_state=1111 )\n",
        "adaboost.fit( Xtrain, y_train_final )"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
              "                   n_estimators=50, random_state=1111)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6A_PCV4LfZB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2178eee6-17f8-4b4b-8df2-5f30d4827a20"
      },
      "source": [
        "ab_train_preds = adaboost.predict(X_train)\n",
        "ab_test_preds = adaboost.predict(X_test)\n",
        "ab_final_preds = adaboost.predict(Xtest)\n",
        "\n",
        "print(bcolors.BOLD + 'aboostCLassifier:' + bcolors.ENDC)\n",
        "print('Train Data: ' + str(f1_score(y_train, ab_train_preds)))\n",
        "print('Test Data:' + str(f1_score(y_test, ab_test_preds)))"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1maboostCLassifier:\u001b[0m\n",
            "Train Data: 0.8789808917197452\n",
            "Test Data:0.8627450980392156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZk4LcAHVbcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_csv('AdaBoost NoSpecial.csv', ab_final_preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6T4N0JIMAgA",
        "colab_type": "text"
      },
      "source": [
        ">>**Zindi Score:** (I had already passed the daily submissions limit at this point, but the score does look promising and I will try again at a later date) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23EU8Q55KQ0K",
        "colab_type": "text"
      },
      "source": [
        ">### Train Test Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVuFeFspIEd-",
        "colab_type": "text"
      },
      "source": [
        "## XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfcCwnkxJVRe",
        "colab_type": "text"
      },
      "source": [
        "### No Trian Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31qxfcc2IIAN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from xgboost import XGBClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWcc0Un4I79-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "0f5d432c-7dfe-4ebb-bd0e-517978991ebf"
      },
      "source": [
        "xgb = XGBClassifier( random_state =  1111 )\n",
        "xgb.fit(Xtrain, y_train_final)"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=1111,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0CrI-2BJRSS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "752bdd22-9ec7-4599-e330-1149c0948377"
      },
      "source": [
        "xgb_train_preds = xgb.predict(X_train)\n",
        "xgb_test_preds = xgb.predict(X_test)\n",
        "xgb_train_o_preds = xgb.predict(Xtrain)\n",
        "xgb_final_preds = xgb.predict(Xtest)\n",
        "\n",
        "print(bcolors.BOLD + 'XGBoostClassifier:' + bcolors.ENDC)\n",
        "print('X_train Data: ' + str(f1_score(y_train, xgb_train_preds)))\n",
        "print('X_test Data:' + str(f1_score(y_test, xgb_test_preds)))\n",
        "print('\\nTrain Data: ' + str(f1_score(y_train_final, xgb_train_o_preds)))"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mXGBoostClassifier:\u001b[0m\n",
            "X_train Data: 0.9538461538461538\n",
            "X_test Data:0.8571428571428572\n",
            "\n",
            "Train Data: 0.9396325459317585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6_qNm9gJ8-k",
        "colab_type": "text"
      },
      "source": [
        "### Train Test Split Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEsBz-Cfa2iA",
        "colab_type": "text"
      },
      "source": [
        "# Conculsion\n",
        ">Because of an unseen limitation in the number of submissions allowed in one day, the best result obtained was a model constructed from the RandomForestClassifer with a random_state of 1111. This model was trained on SMOTE resampled data and it performed the best out of all the other models which I was able to submit to the competition.\n",
        "\n",
        ">It would be interesting to see what kind of score a SMOTE resampled and gridsearchedCV XGBoostClassifier would perform for this competition. Hopefully I can improve my score to an f1_score of above 0.8 in the future.\n",
        "\n",
        ">Fraudulent transactions are rare and resampling was very important in this competition.  I was unable to try various train_test_split test sizes, and I was also unable to test out how MinMaxScaler affects the results as well as adding columns which had earlier crashed the kernel after the get_dummies memory error issue was resolved.\n",
        "\n",
        ">In the end, my intuition for classification and luck helped me get the results I got here. I would have loved to test out everything I wanted and I regret not planning my submissions a bit better.\n",
        "\n",
        "> More function and/or classes should have been used to clean up the code, but that was exchanged for results. This notebook could have also benefitted from more analyses on the features selected and more visuals to understand the data better. These too were exchanged for time and my matplotlib skills are not sophisicated enough to tell a good story."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLZOESgMctiL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}